{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3739e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./jigsaw-toxic-comment-classification-challenge/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2554a868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a92d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.0732213246768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033623e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "obscene           8449\n",
       "insult            7877\n",
       "severe_toxic      1595\n",
       "identity_hate     1405\n",
       "threat             478\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all toxic labels\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Count how many comments belong to each label\n",
    "label_counts = df[labels].sum().sort_values(ascending=False)\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987a00e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pragatibagul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pragatibagul/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/pragatibagul/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Download stop words \n",
    "def preprocess(text):\n",
    "    # remove urls\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+','',text)\n",
    "    # lowercase the entire text\n",
    "    text = text.lower()\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    # remove mentions\n",
    "    text = re.sub(r'@\\w+','',text)\n",
    "    # remove hashtags\n",
    "    text = re.sub(r'#\\w+','',text)\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    # get rid of stop words\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = text.split()\n",
    "    #Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03dd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_text'] = df['comment_text'].apply(preprocess)\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(tokenize_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20680454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate', 'preprocessed_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35089b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification in /opt/anaconda3/lib/python3.11/site-packages (0.1.9)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from iterative-stratification) (1.24.3)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from iterative-stratification) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from iterative-stratification) (1.3.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->iterative-stratification) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->iterative-stratification) (2.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7ae431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full dataset distribution\n",
      "               count    pct\n",
      "toxic          15294  9.584\n",
      "severe_toxic    1595  1.000\n",
      "obscene         8449  5.295\n",
      "threat           478  0.300\n",
      "insult          7877  4.936\n",
      "identity_hate   1405  0.880\n",
      "\n",
      "Train distribution\n",
      "               count    pct\n",
      "toxic          12235  9.584\n",
      "severe_toxic    1276  1.000\n",
      "obscene         6759  5.295\n",
      "threat           382  0.299\n",
      "insult          6302  4.937\n",
      "identity_hate   1124  0.880\n",
      "\n",
      "Validation distribution\n",
      "               count    pct\n",
      "toxic           3059  9.585\n",
      "severe_toxic     319  1.000\n",
      "obscene         1690  5.295\n",
      "threat            96  0.301\n",
      "insult          1575  4.935\n",
      "identity_hate    281  0.880\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "def print_label_dist(df,label_cols,title=''):\n",
    "    counts = df[label_cols].sum().astype(int)\n",
    "    pct = (counts/len(df)*100).round(3)\n",
    "    out = pd.DataFrame({'count':counts,'pct':pct})\n",
    "    print(f'\\n{title}')\n",
    "    print(out)\n",
    "\n",
    "# Quick check of full data label distribution\n",
    "print_label_dist(df,label_cols,'Full dataset distribution')\n",
    "\n",
    "#Create multilabel stratified split (80% train, 20% val)\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# iterstrat expects a 2D array for X\n",
    "X = df['preprocessed_text'].values\n",
    "y = df[label_cols].values\n",
    "\n",
    "train_idx,val_idx = next(msss.split(X,y))\n",
    "train = df.iloc[train_idx].reset_index(drop=True)\n",
    "val = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print_label_dist(train,label_cols,\"Train distribution\")\n",
    "print_label_dist(val,label_cols,\"Validation distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f9a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (127656, 50000) X_val: (31915, 50000) y_train: (127656, 6) y_val: (31915, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "text_col = 'preprocessed_text'\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "max_features = 50000\n",
    "ngram_range = (1,2)\n",
    "C = 1.0\n",
    "model_dir = 'baseline_model'\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "# Input (train, val)\n",
    "df_train = train\n",
    "df_val = val\n",
    "\n",
    "# 1. Convert comments to TF IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            lowercase=True,\n",
    "            token_pattern=r'(?u)\\b\\w+\\b')\n",
    "\n",
    "X_train = tfidf.fit_transform(df_train[text_col].fillna('').astype(str).tolist())\n",
    "X_val = tfidf.transform(df_val[text_col].fillna('').astype(str).tolist())\n",
    "\n",
    "# Multi-label target matrix (shape: n_samples x n_labels)\n",
    "y_train = df_train[label_cols].values\n",
    "y_val = df_val[label_cols].values\n",
    "\n",
    "# Sanity check shapes\n",
    "print('X_train:',X_train.shape,'X_val:',X_val.shape,'y_train:',y_train.shape,'y_val:',y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fd7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression for multi-label\n",
    "base_clf = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=C,\n",
    "    solver='saga',\n",
    "    max_iter=200,\n",
    "    n_jobs=-1,\n",
    "    class_weight=None\n",
    ")\n",
    "\n",
    "clf = OneVsRestClassifier(base_clf,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0797037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Per-label summary\n",
      "toxic           | precision=0.925 recall=0.598 f1=0.726 support=3059\n",
      "severe_toxic    | precision=0.535 recall=0.213 f1=0.305 support=319\n",
      "obscene         | precision=0.925 recall=0.646 f1=0.761 support=1690\n",
      "threat          | precision=0.438 recall=0.073 f1=0.125 support=96\n",
      "insult          | precision=0.827 recall=0.521 f1=0.639 support=1575\n",
      "identity_hate   | precision=0.567 recall=0.135 f1=0.218 support=281\n",
      "\n",
      " Macro F1: 0.4624\n",
      "\n",
      " Micro F1: 0.4624\n"
     ]
    }
   ],
   "source": [
    "#Evaluate using F1 score\n",
    "# Predict binary with default threshold of 0.5 on probabilities\n",
    "y_val_probs = clf.predict_proba(X_val)\n",
    "y_val_pred = (y_val_probs >= 0.5).astype(int)\n",
    "\n",
    "#Per-label metrics\n",
    "precision,recall,f1,support = precision_recall_fscore_support(\n",
    "    y_val,\n",
    "    y_val_pred,\n",
    "    average=None,\n",
    "    labels=range(len(label_cols)))\n",
    "\n",
    "per_label = []\n",
    "for i, lbl in enumerate(label_cols):\n",
    "    per_label.append({\n",
    "        'label':lbl,\n",
    "        'precision':float(precision[i]),\n",
    "        'recall':float(recall[i]),\n",
    "        'f1':float(f1[i]),\n",
    "        'support':int(support[i])\n",
    "    })\n",
    "\n",
    "#Macro and Micro f1\n",
    "macro_f1 = float(f1_score(y_val,y_val_pred,average='macro'))\n",
    "micro_f1 = float(f1_score(y_val,y_val_pred,average='micro'))\n",
    "\n",
    "#Print summary\n",
    "print('\\n Per-label summary')\n",
    "for r in per_label:\n",
    "    print(f\"{r['label']:15s} | precision={r['precision']:.3f} recall={r['recall']:.3f} f1={r['f1']:.3f} support={r['support']}\")\n",
    "\n",
    "print(f'\\n Macro F1: {macro_f1:.4f}')\n",
    "print(f'\\n Micro F1: {macro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "296f5fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved vectorizer, model, and results to: baseline_model\n"
     ]
    }
   ],
   "source": [
    "# Save baseline results\n",
    "joblib.dump(tfidf,os.path.join(model_dir,'tfidf_vectorizer.joblib'))\n",
    "joblib.dump(clf,os.path.join(model_dir,'ovr_logreg.joblib'))\n",
    "\n",
    "#Save evaluation results to JSON/CSV\n",
    "results = {\n",
    "    'per_label':per_label,\n",
    "    'macro_f1':macro_f1,\n",
    "    'micro_f1':micro_f1,\n",
    "    'params':{\n",
    "        'max_features':max_features,\n",
    "        'ngram_range':ngram_range,\n",
    "        'C':C\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir,'baseline_results.json'),'w') as f:\n",
    "    json.dump(results,f,indent=2)\n",
    "    \n",
    "pd.DataFrame(per_label).to_csv(os.path.join(model_dir,'per_label_results.csv'),index=False)\n",
    "print(f\"\\nSaved vectorizer, model, and results to: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f40e2",
   "metadata": {},
   "source": [
    "It trains a pretrained transformer (BERT by default) with a simple linear classifier head, uses BCEWithLogitsLoss, trains for a few epochs, and evaluates on a validation set with per-label and macro F1. It also shows how to tokenize the dataframe column in batches and how to build a Dataset / DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9a3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "MODEL_NAME = 'bert-base-cased'\n",
    "TEXT_COL = 'comment_text'\n",
    "LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 24\n",
    "LR = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "NUM_EPOCHS = 3\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea1cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1,test_size=TEST_SIZE,random_state=RANDOM_STATE)\n",
    "X = np.arange(len(df)).reshape(-1,1)\n",
    "y = df[LABEL_COLS].values\n",
    "train_idx, val_idx = next(msss.split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77ee1d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes -> full :  159571  Train:  127656  Validation :  31915\n"
     ]
    }
   ],
   "source": [
    "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "print('Sizes -> full : ',len(df),' Train: ',len(train_df),' Validation : ',len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "915e5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenising train...\n",
      "Tokenising val...\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer Batch Encode\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def batch_encode_texts(texts,tokenizer,max_length=MAX_LEN,batch_size=512):\n",
    "    input_ids_list = []\n",
    "    attention_masks_list = []\n",
    "    for i in range(0,len(texts),batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "                batch,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        input_ids_list.append(enc['input_ids'])\n",
    "        attention_masks_list.append(enc['attention_mask'])\n",
    "    input_ids = torch.cat(input_ids_list,dim=0)\n",
    "    attention_mask = torch.cat(attention_masks_list,dim=0)\n",
    "    return {'input_ids':input_ids,'attention_mask':attention_mask}\n",
    "\n",
    "print('Tokenising train...')\n",
    "train_enc = batch_encode_texts(train_df[TEXT_COL].astype(str).tolist(),tokenizer)\n",
    "print('Tokenising val...')\n",
    "val_enc = batch_encode_texts(val_df[TEXT_COL].astype(str).tolist(),tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f83619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets + DataLoaders\n",
    "y_train = torch.tensor(train_df[LABEL_COLS].values.astype(float),dtype=torch.float)\n",
    "y_val = torch.tensor(val_df[LABEL_COLS].values.astype(float),dtype=torch.float)\n",
    "\n",
    "train_dataset = TensorDataset(train_enc['input_ids'],train_enc['attention_mask'],y_train)\n",
    "val_dataset = TensorDataset(val_enc['input_ids'],val_enc['attention_mask'],y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "val_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2fcf45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight per label {'toxic': 9.434, 'severe_toxic': 99.044, 'obscene': 17.887, 'threat': 333.178, 'insult': 19.256, 'identity_hate': 112.573}\n"
     ]
    }
   ],
   "source": [
    "# Pos weight for BCE (HELPS WITH IMBALANCE)\n",
    "pos = train_df[LABEL_COLS].sum().values.astype(float)\n",
    "neg = len(train_df) - pos\n",
    "pos_weight_arr = np.where(pos == 0,1.0,neg/np.where(pos==0,1.0,pos))\n",
    "pos_weight = torch.tensor(pos_weight_arr,dtype=torch.float).to(DEVICE)\n",
    "print('pos_weight per label',dict(zip(LABEL_COLS,np.round(pos_weight_arr,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3f49734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: transformer backbone + linear head\n",
    "class TransformerForMultiLabel(nn.Module):\n",
    "    def __init__(self,model_name,num_labels):\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.backbone = AutoModel.from_pretrained(model_name,config=self.config)\n",
    "        self.classifier = nn.Linear(self.backbone.config.hidden_size,num_labels)\n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        out=self.backbone(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:,0,:]\n",
    "        logits = self.classifier(cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e82bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerForMultiLabel(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerForMultiLabel(MODEL_NAME,num_labels=len(LABEL_COLS))\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49382670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(),lr=LR,weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=int(0.05*total_steps),num_training_steps=total_steps)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9357ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval function\n",
    "def evaluate(model,loader,device,threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in tqdm(loader,desc='Eval',leave=False):\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            logits = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            all_labels.append(labels_np)\n",
    "            all_preds.append(preds)\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    per_label_f1 = f1_score(y_true,y_pred,average=None,zero_division=0)\n",
    "    macro_f1 = f1_score(y_true,y_pred,average='macro',zero_division=0)\n",
    "    report = classification_report(y_true,y_pred,target_names=LABEL_COLS,zero_division=0)\n",
    "    return per_label_f1,macro_f1,report\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ed9252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a7a6ed0c3c4c4595ac100fc9ed2926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/5319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 avg loss : 0.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Macro F1: 0.4008\n",
      "Per-label F1: {'toxic': 0.7045, 'severe_toxic': 0.2555, 'obscene': 0.6367, 'threat': 0.0693, 'insult': 0.5688, 'identity_hate': 0.1701}\n",
      "Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.57      0.91      0.70      3059\n",
      " severe_toxic       0.15      0.98      0.26       319\n",
      "      obscene       0.48      0.95      0.64      1690\n",
      "       threat       0.04      0.94      0.07        96\n",
      "       insult       0.41      0.95      0.57      1575\n",
      "identity_hate       0.09      0.98      0.17       281\n",
      "\n",
      "    micro avg       0.34      0.94      0.50      7020\n",
      "    macro avg       0.29      0.95      0.40      7020\n",
      " weighted avg       0.47      0.94      0.61      7020\n",
      "  samples avg       0.04      0.09      0.06      7020\n",
      "\n",
      "Saved best model: best_transformer_multilabel.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeeb74bab2f4f2ebdcf2e9f1433e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/5319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2 avg loss : 0.2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Macro F1: 0.4288\n",
      "Per-label F1: {'toxic': 0.7007, 'severe_toxic': 0.2642, 'obscene': 0.6707, 'threat': 0.1303, 'insult': 0.5913, 'identity_hate': 0.2154}\n",
      "Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.57      0.92      0.70      3059\n",
      " severe_toxic       0.15      0.98      0.26       319\n",
      "      obscene       0.52      0.95      0.67      1690\n",
      "       threat       0.07      0.93      0.13        96\n",
      "       insult       0.43      0.95      0.59      1575\n",
      "identity_hate       0.12      0.98      0.22       281\n",
      "\n",
      "    micro avg       0.38      0.94      0.55      7020\n",
      "    macro avg       0.31      0.95      0.43      7020\n",
      " weighted avg       0.48      0.94      0.62      7020\n",
      "  samples avg       0.05      0.09      0.06      7020\n",
      "\n",
      "Saved best model: best_transformer_multilabel.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e3cd48d31a414eb796e4bb23c73195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/5319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 3 avg loss : 0.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Macro F1: 0.4993\n",
      "Per-label F1: {'toxic': 0.7226, 'severe_toxic': 0.3647, 'obscene': 0.7032, 'threat': 0.2393, 'insult': 0.6292, 'identity_hate': 0.337}\n",
      "Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.60      0.91      0.72      3059\n",
      " severe_toxic       0.23      0.96      0.36       319\n",
      "      obscene       0.56      0.94      0.70      1690\n",
      "       threat       0.14      0.81      0.24        96\n",
      "       insult       0.48      0.93      0.63      1575\n",
      "identity_hate       0.21      0.88      0.34       281\n",
      "\n",
      "    micro avg       0.47      0.92      0.63      7020\n",
      "    macro avg       0.37      0.91      0.50      7020\n",
      " weighted avg       0.52      0.92      0.66      7020\n",
      "  samples avg       0.06      0.09      0.07      7020\n",
      "\n",
      "Saved best model: best_transformer_multilabel.pt\n",
      "Training complete. Best macro F1: 0.4993244255850884\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_macro = -1.0\n",
    "for epoch in range(1,NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(train_loader,desc=f'Epoch {epoch}/{NUM_EPOCHS}')\n",
    "    for input_ids, attention_mask, labels in loop:\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'\\n Epoch {epoch} avg loss : {avg_loss:.4f}')\n",
    "    \n",
    "    # Evaluate\n",
    "    per_label_f1, macro_f1, report = evaluate(model, val_loader, DEVICE, threshold=0.5)\n",
    "    print(\"Validation Macro F1: {:.4f}\".format(macro_f1))\n",
    "    print(\"Per-label F1:\", dict(zip(LABEL_COLS, np.round(per_label_f1, 4))))\n",
    "    print(\"Classification report:\\n\", report)\n",
    "\n",
    "    if macro_f1 > best_macro:\n",
    "        best_macro = macro_f1\n",
    "        save_path = \"best_transformer_multilabel.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'tokenizer_name': MODEL_NAME,\n",
    "            'label_cols': LABEL_COLS,\n",
    "            'max_len': MAX_LEN\n",
    "        }, save_path)\n",
    "        print(\"Saved best model:\", save_path)\n",
    "\n",
    "print(\"Training complete. Best macro F1:\", best_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b15e1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def predict(text,threshold=0.5):\n",
    "    #Tokenize\n",
    "    enc = tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    #Move to CPU or CUDA\n",
    "    input_ids = enc['input_ids']\n",
    "    attention_mask = enc['attention_mask']\n",
    "    \n",
    "    #Forward pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        probs = torch.sigmoid(logits).numpy()[0]\n",
    "        \n",
    "    #Convert probabilities to 0/1\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    \n",
    "    #Map to dictionary\n",
    "    result = {\n",
    "        'probabilities':dict(zip(LABEL_COLS,np.round(probs,4))),\n",
    "        'predictions':dict(zip(LABEL_COLS,preds.astype(int)))\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2069cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You are a complete idiot'\n",
    "output = predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d933487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities :  {'toxic': 0.9938, 'severe_toxic': 0.2402, 'obscene': 0.9714, 'threat': 0.0198, 'insult': 0.9944, 'identity_hate': 0.0311}\n",
      "Binary Predictions :  {'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Probabilities : ',output['probabilities'])\n",
    "print('Binary Predictions : ',output['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1e2bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities :  {'toxic': 0.9978, 'severe_toxic': 0.8452, 'obscene': 0.993, 'threat': 0.0261, 'insult': 0.9977, 'identity_hate': 0.1857}\n",
      "Binary Predictions :  {'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n"
     ]
    }
   ],
   "source": [
    "text = 'You are a piece of shit. You scoundrel!'\n",
    "output = predict(text)\n",
    "print('Probabilities : ',output['probabilities'])\n",
    "print('Binary Predictions : ',output['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5e6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
